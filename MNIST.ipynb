{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO31buKaAFeyXl/F3xFPs4C",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/faranhaider1/MNIST/blob/main/MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "RLhDO4K0YoN0"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch import nn, optim\n",
        "from torchvision.datasets import MNIST\n",
        "import torchvision.transforms.functional as TF\n",
        "import numpy as np\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "from torch import nn, optim, save, load"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom function to resize and crop images to a target size of 20x20 pixels\n",
        "def resize_and_crop_image(image, target_size=(20, 20)):\n",
        "    # Resizes the given image to the specified dimensions\n",
        "    resized_image = TF.resize(image, target_size)\n",
        "    return resized_image\n",
        "\n",
        "# Custom data loader function to manually process, batch, and load data\n",
        "def custom_data_loader(dataset, batch_size, shuffle=True):\n",
        "    # Creates an array of indices for the dataset, allowing for optional shuffling\n",
        "    indices = np.arange(len(dataset))\n",
        "    if shuffle:\n",
        "        # Shuffles indices to randomize data order\n",
        "        np.random.shuffle(indices)\n",
        "\n",
        "    # Iterates over the dataset in batches of specified size\n",
        "    for start_idx in range(0, len(dataset), batch_size):\n",
        "        batch_indices = indices[start_idx:start_idx + batch_size]\n",
        "        batch_images = []\n",
        "        batch_labels = []\n",
        "\n",
        "        # Processes each image in the current batch\n",
        "        for i in batch_indices:\n",
        "            image, label = dataset[i]\n",
        "            # Applies resizing and converts the image to a tensor\n",
        "            image = resize_and_crop_image(image)\n",
        "            batch_images.append(TF.to_tensor(image))\n",
        "            batch_labels.append(label)\n",
        "\n",
        "        # Converts lists of images and labels to tensor batches\n",
        "        batch_images_tensor = torch.stack(batch_images)\n",
        "        batch_labels_tensor = torch.tensor(batch_labels)\n",
        "\n",
        "        # Yields a batch of images and labels as tensors\n",
        "        yield batch_images_tensor, batch_labels_tensor\n",
        "\n",
        "# Image Classifier Model with Custom Architecture\n",
        "class ImageClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ImageClassifier, self).__init__()\n",
        "        # Convolutional layers with padding to maintain image size\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
        "        # Third layer with adjusted input channels to accommodate feature stacking\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(64 + 32, 64, kernel_size=3, padding=1)\n",
        "        # Fully connected layer, assuming input size is 20x20 pixels post-resizing\n",
        "        self.fc = nn.Linear(64 * 20 * 20, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        #Add the input of the first layer to its output\n",
        "        x1 = F.relu(self.conv1(x))\n",
        "\n",
        "        # Resize original input to match x1 dimensions if necessary and add\n",
        "        x1_added = x1 + F.interpolate(x, size=x1.size()[2:])\n",
        "\n",
        "        # Pass result through second convolutional layer\n",
        "        x2 = F.relu(self.conv2(x1_added))\n",
        "\n",
        "        # Task 5: Stack the feature map from x2 with x1_added for the third layer\n",
        "        x2_stacked = torch.cat((x2, x1_added), dim=1)\n",
        "\n",
        "        # Pass stacked feature maps through third convolutional layer\n",
        "        x3 = F.relu(self.conv3(x2_stacked))\n",
        "\n",
        "        # Flatten the output for the fully connected layer\n",
        "        x_flattened = torch.flatten(x3, 1)\n",
        "\n",
        "        # Calculate class scores\n",
        "        out = self.fc(x_flattened)\n",
        "        return out\n",
        "\n",
        "# Initialize model, loss function, and optimizer\n",
        "model = ImageClassifier().to('cpu')\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "# Training loop\n",
        "if __name__ == \"__main__\":\n",
        "    # Load MNIST dataset without any initial transformations\n",
        "    train_dataset = MNIST(root=\"data\", train=True, download=True, transform=None)\n",
        "\n",
        "    # Specify batch size and initialize custom data loader\n",
        "    batch_size = 32\n",
        "    epochs = 10\n",
        "    custom_loader = custom_data_loader(train_dataset, batch_size)\n",
        "\n",
        "    # Train for a specified number of epochs\n",
        "    for epoch in range(epochs):\n",
        "        for batch_images, batch_labels in custom_loader:\n",
        "            # Zero gradients, perform forward pass, compute loss, and backpropagate\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(batch_images)\n",
        "            loss = loss_fn(outputs, batch_labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        # Print loss after each epoch for monitoring\n",
        "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss.item()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v6bBKBA7Y3kA",
        "outputId": "f2f04331-db24-4f9c-b355-96322a6a6597"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 0.006955201271921396\n",
            "Epoch 2/10, Loss: 0.006955201271921396\n",
            "Epoch 3/10, Loss: 0.006955201271921396\n",
            "Epoch 4/10, Loss: 0.006955201271921396\n",
            "Epoch 5/10, Loss: 0.006955201271921396\n",
            "Epoch 6/10, Loss: 0.006955201271921396\n",
            "Epoch 7/10, Loss: 0.006955201271921396\n",
            "Epoch 8/10, Loss: 0.006955201271921396\n",
            "Epoch 9/10, Loss: 0.006955201271921396\n",
            "Epoch 10/10, Loss: 0.006955201271921396\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For simplicity, this snippet assumes the model is already trained\n",
        "# and focuses on the saving, loading, and inference parts\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Save the model state\n",
        "    model_path = '/content/data/model_state.pt'  # Adjusted path for compatibility with this environment\n",
        "    with open(model_path, 'wb') as f:\n",
        "        save(model.state_dict(), f)\n",
        "\n",
        "    # Load the model state\n",
        "    with open(model_path, 'rb') as f:\n",
        "        model.load_state_dict(load(f))\n",
        "\n",
        "    # Prepare an image for inference\n",
        "    img_path = '/content/img_2.jpg'  # uploading image\n",
        "    img = Image.open(img_path)\n",
        "\n",
        "    # Assuming the image is grayscale, similar to MNIST dataset images\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Grayscale(num_output_channels=1),\n",
        "        transforms.Resize((20, 20)),  # Resize to match the input size of the model\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5,), (0.5,))  # Assuming normalization similar to the training phase\n",
        "    ])\n",
        "\n",
        "    img_tensor = transform(img).unsqueeze(0).to('cpu')  # Add batch dimension and move to the correct device\n",
        "\n",
        "    # Perform inference\n",
        "    output = model(img_tensor)\n",
        "    predicted_class = torch.argmax(output, dim=1)\n",
        "    print(f\"Predicted class: {predicted_class.item()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ccmSsvBnaBra",
        "outputId": "b37e2858-7d85-4c0e-fa53-49ebc8e01191"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted class: 0\n"
          ]
        }
      ]
    }
  ]
}